# Arabic-GEC
Neural-based automatic Arabic Grammar Error Correction (AGEC) model based on sequence-to-sequence multi-heads attentions Transformer. Initially, we introduce a an unsupervised method to generate a large-scale synthetic dataset based on confusion function to increase the amount of training set. 
# Model requirements
Regarding load and run the trained models it requires a working installation of following: 
- pytorch-transformers==1.2.0
- torchtext==0.4.0
- numpy==1.17.0
- pandas==1.17.0
- payArabic
- bpemb
- NLTK
